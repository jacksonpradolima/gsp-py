name: Benchmarks

on:
  schedule:
    - cron: "0 6 * * 1"
  workflow_dispatch:
    inputs:
      run_python_backend:
        description: "Run Python backend baseline (skips Rust build)"
        required: false
        default: false
        type: boolean

jobs:
  rust-benchmark:
    name: Rust backend
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Set up Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6.0.0
        with:
          python-version: "3.13"

      - name: Install uv
        uses: astral-sh/setup-uv@f06b870e0a91d23284a3013acc55e6f88ab4b904 # v7.0.0
        with:
          python-version: "3.13"
          enable-cache: true

      - name: Sync dependencies
        run: |
          set -euo pipefail
          uv venv .venv --python 3.13 --allow-existing
          uv sync --frozen --extra dev

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@4be9e76fd7c4901c61fb841f559994984270fce7 # stable

      - name: Build Rust backend
        run: make rust-build

      - name: Run benchmark (Rust backend)
        env:
          GSPPY_BACKEND: rust
        run: |
          set -euo pipefail
          uv run python benchmarks/bench_support.py \
            --n_tx 5000 \
            --tx_len 6 \
            --vocab 200 \
            --min_support 0.2 \
            --warmup \
            | tee benchmark_rust.log

      - name: Extract metrics
        id: metrics_rust
        run: |
          set -euo pipefail
          python - <<'PY'
          import json
          import pathlib
          import re
          import time

          log_path = pathlib.Path("benchmark_rust.log")
          log = log_path.read_text()

          py_match = re.search(r"Python:\s*([0-9.]+)s", log)
          rs_match = re.search(r"Rust:\s*([0-9.]+)s", log)

          data = {
              "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
              "backend": "rust",
              "n_tx": 5000,
              "tx_len": 6,
              "vocab": 200,
              "min_support": 0.2,
          }

          if py_match:
              data["python_time_s"] = float(py_match.group(1))
          if rs_match:
              data["rust_time_s"] = float(rs_match.group(1))

          if py_match and rs_match:
              py_time = float(py_match.group(1))
              rs_time = float(rs_match.group(1))
              if rs_time > 0:
                  data["speedup_x"] = py_time / rs_time
              if py_time > 0:
                  data["improvement_pct"] = (py_time - rs_time) / py_time * 100
              else:
                  data["improvement_pct"] = None

          pathlib.Path("benchmark_rust.json").write_text(json.dumps(data, indent=2))
          PY

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: rust-benchmark
          path: |
            benchmark_rust.log
            benchmark_rust.json

  python-benchmark:
    name: Python baseline
    if: (github.event_name == 'workflow_dispatch' && inputs.run_python_backend == true) || github.event_name == 'schedule'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1

      - name: Set up Python
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6.0.0
        with:
          python-version: "3.13"

      - name: Install uv
        uses: astral-sh/setup-uv@f06b870e0a91d23284a3013acc55e6f88ab4b904 # v7.0.0
        with:
          python-version: "3.13"
          enable-cache: true

      - name: Sync dependencies
        run: |
          set -euo pipefail
          uv venv .venv --python 3.13 --allow-existing
          uv sync --frozen --extra dev

      - name: Run benchmark (Python backend)
        env:
          GSPPY_BACKEND: python
        run: |
          set -euo pipefail
          uv run python benchmarks/bench_support.py \
            --n_tx 5000 \
            --tx_len 6 \
            --vocab 200 \
            --min_support 0.2 \
            --warmup \
            | tee benchmark_python.log

      - name: Extract metrics
        id: metrics_python
        run: |
          set -euo pipefail
          python - <<'PY'
          import json
          import pathlib
          import re
          import time

          log = pathlib.Path("benchmark_python.log").read_text()
          py_match = re.search(r"Python:\s*([0-9.]+)s", log)

          data = {
              "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
              "backend": "python",
              "n_tx": 5000,
              "tx_len": 6,
              "vocab": 200,
              "min_support": 0.2,
          }

          if py_match:
              data["python_time_s"] = float(py_match.group(1))

          pathlib.Path("benchmark_python.json").write_text(json.dumps(data, indent=2))
          PY

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: python-benchmark
          path: |
            benchmark_python.log
            benchmark_python.json
